{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "QQP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkothiwala/QuoraQuestionPairs/blob/master/QQP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piBU_Qo4DSK6",
        "colab_type": "text"
      },
      "source": [
        "# Data Download (Competition Data, Embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7O7U4XeDK8A",
        "colab_type": "text"
      },
      "source": [
        "Kaggle API Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1a-pMNd-Roy",
        "colab_type": "code",
        "outputId": "d8a81b93-098f-4aa0-f99c-6bb2f035ba4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp ./kaggle.json ~/.kaggle/kaggle.json #Need to upload kaggle.json file from C:\\Users\\<USERNAME>\\.kaggle\\"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.6.16)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7QuC6LSCaOo",
        "colab_type": "text"
      },
      "source": [
        "### Download Competition Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTRdGzC8AEYB",
        "colab_type": "code",
        "outputId": "ee940529-34fa-40c8-c71e-4c1a4c75a2cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "# Downloading Data\n",
        "!kaggle competitions download -c quora-question-pairs\n",
        "# Extracting the data\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('train.csv.zip', 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()\n",
        "zip_ref = zipfile.ZipFile('test.csv.zip', 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Downloading test.csv.zip to /content\n",
            " 93% 105M/112M [00:02<00:00, 37.0MB/s] \n",
            "100% 112M/112M [00:03<00:00, 39.0MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tY9gzRK4CVkz",
        "colab_type": "text"
      },
      "source": [
        "### Download GloVe Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raNXr4PS_Uvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import progressbar\n",
        "pbar = None\n",
        "\n",
        "def show_progress(block_num, block_size, total_size):\n",
        "    global pbar\n",
        "    if pbar is None:\n",
        "        pbar = progressbar.ProgressBar(maxval=total_size)\n",
        "\n",
        "    downloaded = block_num * block_size\n",
        "    if downloaded < total_size:\n",
        "        pbar.update(downloaded)\n",
        "    else:\n",
        "        pbar.finish()\n",
        "        pbar = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve9IkY1_BDHL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "40d38c58-fd61-448b-bd7e-071c40001538"
      },
      "source": [
        "# Lets Download GloVe Embeddings\n",
        "import os\n",
        "import urllib.request\n",
        "print('downloading zipfile')\n",
        "urllib.request.urlretrieve('http://nlp.stanford.edu/data/glove.840B.300d.zip', 'glove840B.zip', show_progress)\n",
        "print('extracting zip file')\n",
        "# Unzip the Embeddings\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('glove840B.zip', 'r')\n",
        "zip_ref.extractall('embeddings')\n",
        "zip_ref.close()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading zipfile\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (2176768927 of 2176768927) |########| Elapsed Time: 0:04:32 Time:  0:04:32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "extracting zip file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5Ka_Vm4COrv",
        "colab_type": "text"
      },
      "source": [
        "### Load Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8O5GNh5CNJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_embed(file):\n",
        "    def get_coefs(word,*arr): \n",
        "        return word, np.asarray(arr, dtype='float32')\n",
        "    \n",
        "    if file == '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec':\n",
        "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file) if len(o)>100)\n",
        "    else:\n",
        "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n",
        "        \n",
        "    return embeddings_index\n",
        "\n",
        "# Load embedded vectors\n",
        "glove = './embeddings/glove.840B.300d.txt'\n",
        "#embed_glove = load_embed(glove) #We should load it only when required later"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-oIp3PJDClS",
        "colab_type": "text"
      },
      "source": [
        "# Start Point of the Notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJo_LPkozXUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "%matplotlib inline\n",
        "\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "#%%capture\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "#tqdm().pandas()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrot3TtFzXUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('train.csv').dropna()\n",
        "test_df = pd.read_csv('test.csv').dropna()\n",
        "#test_df = pd.read_csv('../input/test.csv').dropna()\n",
        "q1 = train_df.question1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmPAkVGqzXUs",
        "colab_type": "text"
      },
      "source": [
        "## 1 Text Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20u9ElUHzXUw",
        "colab_type": "text"
      },
      "source": [
        "### 1.1. Put sentence between Start Stop Token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjmi9X_ZzXUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def addStartStopTokens(series):\n",
        "    return '<start> ' + series.str.lower() + ' <stop>'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OigeszyOzXU7",
        "colab_type": "text"
      },
      "source": [
        "### 1.2. replace numbers with \"number\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgmGVDi0zXVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replaceNumbers(series):\n",
        "    # Space around number is added to ensure that\n",
        "    # number was a single entity and not with a word (e.g. F1 visa, Audi A4)\n",
        "    total = series.str.contains(' [\\d]+ ').sum()\n",
        "    print(\"{:.2f} % queries with numbers were processed\".format(total*100/len(series)))\n",
        "    return series.str.replace(' [+-]?([0-9]*[.])?[0-9]+ ',' number ')#.replace(' [\\d]+(.[\\d]+) ',' number ') # Still misses case of float numbers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj6LUarSzXVI",
        "colab_type": "text"
      },
      "source": [
        "### 1.3. add space around non alpha-numeric chars"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXqXZ0MjzXVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def processNonAlNumChars(series):\n",
        "    # '\\1' does not work with out `r` prefix and () grouping\n",
        "    return series.str.replace(r'([^0-9a-zA-Z\\' ]+)',r' \\1 ') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJe9sbnHzXVX",
        "colab_type": "text"
      },
      "source": [
        "### 1.4. ephostropis\n",
        "\n",
        "1. Three (including apostrophe) long: I'm, I'd\n",
        "2. Four long: it's, I've, he's, I'll, he'd, we'd, it'd\n",
        "3. Five long: don't, can't, we're, isn't, won't, we've, we'll, she's, you'd, let's, who's, he'll, it'll, she'd, ain't, who'd\n",
        "4. Six long: that's, didn't, you're, you'll, what's, wasn't, you've, aren't, here's, hasn't, hadn't, they'd, here's, who've, she'll, who'll, that'd\n",
        "5. Seven long: doesn't, there's, they're, world's, haven't, they've, weren't, they'll, o'clock, mustn't, needn't, must've, that'll\n",
        "6. Eight long: couldn't, wouldn't, could've, would've, there'll\n",
        "7. Nine long: shouldn't, should've\n",
        "\n",
        "Most of the words follow certain pattern with certain exceptions like let's, can't, ain't, shan't - can be ignored<br>\n",
        "These words needs to be converted first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjcT_JtlzXVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def processAphostrophies(series):\n",
        "    '''\n",
        "    Before calling this function, make sure that `space around alphaNum chars are not added`\n",
        "    '''\n",
        "    series = series.str.replace(\" can't \", ' cannot ')\n",
        "    series = series.str.replace(\" ain't \", ' arenot ')\n",
        "    series = series.str.replace(\" won't \", ' willnot ')\n",
        "    series = series.str.replace(\" let's \", ' letus ')# Should I have preceeding space ? (fails for i'm a boy)\n",
        "    series = series.str.replace(r\"([a-z]+)'m \", r\"\\1 am \")\n",
        "    series = series.str.replace(r\"([a-z]+)'d \", r\"\\1 had \")\n",
        "    series = series.str.replace(r\"([a-z]+)'s \", r\"\\1 is \")\n",
        "    series = series.str.replace(r\"([a-z]+)'ve \", r\"\\1 have \")\n",
        "    series = series.str.replace(r\"([a-z]+)'ll \", r\"\\1 will \")\n",
        "    series = series.str.replace(r\"([a-z]+)n't \", r\"\\1 not \")\n",
        "    series = series.str.replace(r\"([a-z]+)'re \", r\"\\1 are \")\n",
        "    return series"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf4ZHOiZzXVn",
        "colab_type": "text"
      },
      "source": [
        "### 1.5 - Remove non-ASCII charecters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XGgfP45zXVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def removeNonASCII(series):\n",
        "    return series.str.replace(r'[^\\x00-\\x7F]+',' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqGiPrbVzXV4",
        "colab_type": "text"
      },
      "source": [
        "### 1.6 - Price related preprocessing (20k, 100m / 100mn, 2b / 1bn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzrFNbgjzXV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def processPriceAcronyms(series):\n",
        "    series = series.str.replace(r\" ([\\d]+)(k|m|mn|b|bn) \",r\" \\1 \") #While fixing 10k, 5bn i found mg, kg, mb etc\n",
        "    #series.str.replace(r\"([\\d]+)([a-z]{1,2,3})\",r\" \\1 \\2 \") # generalizes upto 3 chars (to include kgs, rpm as well)\n",
        "    return series.str.replace(r\"([\\d]+)(mg|gm|kg|kb|mb|gb|tb)\",r\" \\1 \\2 \") #targets only specific words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmeumRITzXWJ",
        "colab_type": "text"
      },
      "source": [
        "### 1.7 - misc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoV8Uio3zXWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def alternatives(series):\n",
        "    series = series.str.replace(r\"(no|some|any)body\",r\"\\1one\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKRxEof9zXWS",
        "colab_type": "text"
      },
      "source": [
        "## 2. Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "651Sm5kozXWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleanText(series):\n",
        "    series = addStartStopTokens(series)\n",
        "    series = replaceNumbers(series)\n",
        "    series = processNonAlNumChars(series) # It will seperate apostrophies as well\n",
        "    series = replaceNumbers(series)\n",
        "\n",
        "    series = processAphostrophies(series)\n",
        "    series = replaceNumbers(series)\n",
        "\n",
        "    series = series.str.replace(\"'\",\" ' \")\n",
        "    series = removeNonASCII(series)\n",
        "    series = replaceNumbers(series)\n",
        "\n",
        "    series = processPriceAcronyms(series)\n",
        "    series = replaceNumbers(series)\n",
        "    series = series.str.replace(r\"[ ]+\",\" \")\n",
        "    return series    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdE6JCZszXWh",
        "colab_type": "code",
        "outputId": "097efa0f-23cb-48ff-a7b6-a17b4f649132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "cleanedQ1 = cleanText(train_df.question1)\n",
        "cleanedQ2 = cleanText(train_df.question2)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.57 % queries with numbers were processed\n",
            "4.60 % queries with numbers were processed\n",
            "0.00 % queries with numbers were processed\n",
            "0.11 % queries with numbers were processed\n",
            "0.44 % queries with numbers were processed\n",
            "5.81 % queries with numbers were processed\n",
            "4.76 % queries with numbers were processed\n",
            "0.01 % queries with numbers were processed\n",
            "0.11 % queries with numbers were processed\n",
            "0.45 % queries with numbers were processed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyt1GgrCt6aK",
        "colab_type": "code",
        "outputId": "aa513746-bfdc-4e1d-d20e-55654ced60b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "cleanedQ1_test = cleanText(test_df.question1)\n",
        "cleanedQ2_test = cleanText(test_df.question2)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.92 % queries with numbers were processed\n",
            "5.09 % queries with numbers were processed\n",
            "0.00 % queries with numbers were processed\n",
            "0.11 % queries with numbers were processed\n",
            "0.48 % queries with numbers were processed\n",
            "5.99 % queries with numbers were processed\n",
            "5.15 % queries with numbers were processed\n",
            "0.01 % queries with numbers were processed\n",
            "0.11 % queries with numbers were processed\n",
            "0.48 % queries with numbers were processed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_4H80AtzXWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleanedQ1 = cleanedQ1.str.replace(' < start > ','')\n",
        "cleanedQ1 = cleanedQ1.str.replace(' < stop > ','')\n",
        "cleanedQ2 = cleanedQ2.str.replace(' < start > ','')\n",
        "cleanedQ2 = cleanedQ2.str.replace(' < stop > ','')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7KMA9LXvzlP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleanedQ1_test = cleanedQ1_test.str.replace(' < start > ','')\n",
        "cleanedQ1_test = cleanedQ1_test.str.replace(' < stop > ','')\n",
        "cleanedQ2_test = cleanedQ2_test.str.replace(' < start > ','')\n",
        "cleanedQ2_test = cleanedQ2_test.str.replace(' < stop > ','')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwlvzMdkzXWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.question1 = cleanedQ1\n",
        "train_df.question2 = cleanedQ2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkyWqP_8wX4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.question1 = cleanedQ1_test\n",
        "test_df.question2 = cleanedQ2_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPUdR2JMzXW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_df.to_csv('processed questions.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhy-8AP4zXXB",
        "colab_type": "text"
      },
      "source": [
        "### Now we have processed data and will not get back again"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaZC_lPyzXXD",
        "colab_type": "text"
      },
      "source": [
        "## 3. Score Calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVnvybKrzXXJ",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 Processing for only score calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CQmOmauEnX7",
        "colab_type": "code",
        "outputId": "e6fd8b40-6381-40c1-fdd6-28261471bd20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdMZQKwgzXXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stop_words = set(stopwords.words('english'))\n",
        "stop_words = ['a', 'an', 'the', 'i', 'my','me','we', 'u', 'you', 'your', 'he', 'his', 'him', 'she', 'her', 'they', 'them', 'y']\n",
        "# Should we remove is, are, of, by, it, its, to, in etc. ?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHOF0o9OzXXU",
        "colab_type": "code",
        "outputId": "520a4ede-8771-456a-8c22-7ae7fdab4cdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentences_q1 = cleanedQ1.str.replace(r'([^0-9a-zA-Z ]+)',r' ').str.replace(r\"[ ]+\",\" \").to_numpy() # Remove NonAlNum Chars \n",
        "filtered_sentences_q1 = []\n",
        "\n",
        "for sentence in tqdm(sentences_q1):\n",
        "    filtered_sentence = [w for w in word_tokenize(sentence) if not w in stop_words] \n",
        "    filtered_sentences_q1.append(filtered_sentence)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d856abbd36949ccb30369940ed2debb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=404287), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2jAcs6azXXi",
        "colab_type": "code",
        "outputId": "754a703d-b3de-4274-dee4-af2f6ef1ad77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentences_q2 = cleanedQ2.str.replace(r'([^0-9a-zA-Z ]+)',r' ').str.replace(r\"[ ]+\",\" \").to_numpy() # Remove NonAlNum Chars \n",
        "filtered_sentences_q2 = []\n",
        "\n",
        "for sentence in tqdm(sentences_q2):\n",
        "    filtered_sentence = [w for w in word_tokenize(sentence) if not w in stop_words] \n",
        "    filtered_sentences_q2.append(filtered_sentence)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "922cb591624d463690885a978d70bb06",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=404287), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcDy5COWwnsN",
        "colab_type": "code",
        "outputId": "c06cddb3-da4b-4014-a18b-128f69fbc20b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentences_q1_test = cleanedQ1_test.str.replace(r'([^0-9a-zA-Z ]+)',r' ').str.replace(r\"[ ]+\",\" \").to_numpy() # Remove NonAlNum Chars \n",
        "filtered_sentences_q1_test = []\n",
        "\n",
        "for sentence in tqdm(sentences_q1_test):\n",
        "    filtered_sentence = [w for w in word_tokenize(sentence) if not w in stop_words] \n",
        "    filtered_sentences_q1_test.append(filtered_sentence)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6995d16062364a358aa8fa206580dd85",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=2345790), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQGFEwPew4f_",
        "colab_type": "code",
        "outputId": "faff78eb-3956-4f82-eccf-74a0a5036953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentences_q2_test = cleanedQ1_test.str.replace(r'([^0-9a-zA-Z ]+)',r' ').str.replace(r\"[ ]+\",\" \").to_numpy() # Remove NonAlNum Chars \n",
        "filtered_sentences_q2_test = []\n",
        "\n",
        "for sentence in tqdm(sentences_q2_test):\n",
        "    filtered_sentence = [w for w in word_tokenize(sentence) if not w in stop_words] \n",
        "    filtered_sentences_q2_test.append(filtered_sentence)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae6bd17bb02b4e62874f161855503783",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=2345790), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OQFrSn6zXXs",
        "colab_type": "text"
      },
      "source": [
        "#### Calculating Scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLtX_-yTzXXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calcScores(filteredSentences1,filteredSentences2):\n",
        "  scores_wo_weight = []\n",
        "  scores_pow1 = [] # Score with exp weight of power 1\n",
        "  scores_pow2 = [] # Score with exp weight of power 2\n",
        "  #for q1, q2 in tqdm(zip(filtered_sentences_q1,filtered_sentences_q2)):\n",
        "  for q1, q2 in tqdm(zip(filteredSentences1,filteredSentences2)):\n",
        "    l1 = len(q1)\n",
        "    l2 = len(q2)\n",
        "    if(l1 == 0 or l2 == 0):\n",
        "        # There some points in data with single chars like ? . ! etc as Q1 or Q2 that endup with expty string\n",
        "        scores_wo_weight.append(0)\n",
        "        scores_pow1.append(0)\n",
        "        scores_pow2.append(0)\n",
        "    else:\n",
        "        overlap = len(set(q1) & set(q2))\n",
        "        weight_pow1 = np.power(np.e, -1/(np.sqrt(l1*l2)))\n",
        "        weight_pow2 = np.power(np.e, -2/(np.sqrt(l1*l2)))\n",
        "        if(weight_pow1 > 1 or weight_pow2 > 1):\n",
        "            print(weight_pow1,weight_pow2)\n",
        "            print(q1, q2)\n",
        "        normalizer = 1/np.sqrt(l1*l2)\n",
        "        scores_wo_weight.append(overlap*normalizer)\n",
        "        scores_pow1.append(overlap*normalizer*weight_pow1)\n",
        "        scores_pow2.append(overlap*normalizer*weight_pow2)   \n",
        "  return scores_wo_weight, scores_pow1, scores_pow2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRXmW6yc0Q-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3198c959-e562-4528-8c47-194bd47bbd64"
      },
      "source": [
        "scores_wo_weight, scores_pow1, scores_pow2 = calcScores(filtered_sentences_q1, filtered_sentences_q2)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6cd91662915d472f92bc8bf4358c24fe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jpjrVpF0kV1",
        "colab_type": "code",
        "outputId": "84aaa22e-1728-4f0d-e26e-e312b7d5810e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "scores_wo_weight_test, scores_pow1_test, scores_pow2_test = calcScores(filtered_sentences_q1_test, filtered_sentences_q2_test)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd48e12631534461afbfbc56afdf5566",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yG58SQLzXX6",
        "colab_type": "text"
      },
      "source": [
        "### Weight Plot Function\n",
        "<img src=\"https://github.com/arkothiwala/QuoraQuestionPairs/blob/master/exponential_weight_plot_desmos%20-%20Copy.png?raw=1\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbWY__KOzXX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS0M2N4vzXYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['scores_wo_weight'] = scores_wo_weight\n",
        "train_df['scores_pow1'] = scores_pow1\n",
        "train_df['scores_pow2'] = scores_pow2\n",
        "train_df['q1_tokens'] = filtered_sentences_q1\n",
        "train_df['q2_tokens'] = filtered_sentences_q2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCl8O2YHzXYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.to_csv('processed_with_weights.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n8FMwmE2EIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['scores_wo_weight'] = scores_wo_weight_test\n",
        "test_df['scores_pow1'] = scores_pow1_test\n",
        "test_df['scores_pow2'] = scores_pow2_test\n",
        "test_df['q1_tokens'] = filtered_sentences_q1_test\n",
        "test_df['q2_tokens'] = filtered_sentences_q2_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VVTGNzz3LJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbeDvo3O22dN",
        "colab_type": "code",
        "outputId": "c700f11d-a9c7-4399-f7ed-2167cac1a640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "test_df.drop(test_df.columns[[1, 2]], axis=1).head()\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_id</th>\n",
              "      <th>scores_wo_weight</th>\n",
              "      <th>scores_pow1</th>\n",
              "      <th>scores_pow2</th>\n",
              "      <th>q1_tokens</th>\n",
              "      <th>q2_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.814354</td>\n",
              "      <td>0.736858</td>\n",
              "      <td>[how, does, surface, pro, himself, number, com...</td>\n",
              "      <td>[how, does, surface, pro, himself, number, com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.920044</td>\n",
              "      <td>0.846482</td>\n",
              "      <td>[should, have, hair, transplant, at, age, numb...</td>\n",
              "      <td>[should, have, hair, transplant, at, age, numb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.843374</td>\n",
              "      <td>0.775942</td>\n",
              "      <td>[what, but, is, best, way, to, send, money, fr...</td>\n",
              "      <td>[what, but, is, best, way, to, send, money, fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.778801</td>\n",
              "      <td>0.606531</td>\n",
              "      <td>[which, food, not, emulsifiers]</td>\n",
              "      <td>[which, food, not, emulsifiers]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.778801</td>\n",
              "      <td>0.606531</td>\n",
              "      <td>[how, aberystwyth, start, reading]</td>\n",
              "      <td>[how, aberystwyth, start, reading]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   test_id  ...                                          q2_tokens\n",
              "0        0  ...  [how, does, surface, pro, himself, number, com...\n",
              "1        1  ...  [should, have, hair, transplant, at, age, numb...\n",
              "2        2  ...  [what, but, is, best, way, to, send, money, fr...\n",
              "3        3  ...                    [which, food, not, emulsifiers]\n",
              "4        4  ...                 [how, aberystwyth, start, reading]\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIWeOM0_2QGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.drop(test_df.columns[[1, 2]], axis=1).to_csv('processed_with_weights_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ShCBviO5Nt0",
        "colab_type": "code",
        "outputId": "386f58e2-4037-468a-8c68-1109647cfc24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import gc\n",
        "del scores_wo_weight_test, scores_pow1_test, scores_pow2_test, scores_wo_weight, scores_pow1, scores_pow2\n",
        "del filtered_sentences_q1_test, filtered_sentences_q2_test, filtered_sentences_q1, filtered_sentences_q2\n",
        "del sentences_q2_test, sentences_q1_test, sentences_q1, sentences_q2\n",
        "del cleanedQ1_test, cleanedQ2_test, cleanedQ1, cleanedQ2\n",
        "gc.collect()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBxmr2L5zXYc",
        "colab_type": "text"
      },
      "source": [
        "### Huge mistake that I had made in score calculation (one silly and other conceptual)\n",
        "\n",
        "When creating a new column for scores_wo_weight, scores_pow1, scores_pow2... I had created something like pd.Series(scores_wo_weight) and so... \n",
        "\n",
        "1) Conceptual Mistake: Now the problem that happend was with <b>dropna</b>. It had dropped perticular indexes from df... When creating a series, it recreated indexes and assigned values accordingly... So I had three lines in the last rows being NaN for scores... The fix was to assign array directly and it took care of indexes\n",
        "\n",
        "2) Silly Mistake: when l1 or l2 was zero I was appending 0 <b>twice</b> in scores_pow1 instead of once in both <b>scores_pow1</b> and <b>scores_pow2</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvjIDXHczXYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(12,16))\n",
        "plt.suptitle(\"Question Pair OverlapScore Distribution\", size=20)\n",
        "plt.subplot(3,2,1)\n",
        "plt.title('IsDuplicate = 0 & NoWeight')\n",
        "train_df[train_df.is_duplicate == 0].scores_pow2.hist(bins=20)\n",
        "plt.subplot(3,2,2)\n",
        "plt.title('IsDuplicate = 1 & NoWeight')\n",
        "train_df[train_df.is_duplicate == 1].scores_pow2.hist(bins=20)\n",
        "plt.subplot(3,2,3)\n",
        "plt.title('IsDuplicate = 0 & P1 Exp Decay')\n",
        "train_df[train_df.is_duplicate == 0].scores_wo_weight.hist(bins=20)\n",
        "plt.subplot(3,2,4)\n",
        "plt.title('IsDuplicate = 1 & P1 Exp Decay')\n",
        "train_df[train_df.is_duplicate == 1].scores_wo_weight.hist(bins=20)\n",
        "plt.subplot(3,2,5)\n",
        "plt.title('IsDuplicate = 0 & P2 Exp Decay')\n",
        "train_df[train_df.is_duplicate == 0].scores_pow1.hist(bins=20)\n",
        "plt.subplot(3,2,6)\n",
        "plt.title('IsDuplicate = 1 & P2 Exp Decay')\n",
        "train_df[train_df.is_duplicate == 1].scores_pow1.hist(bins=20)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnK_lcJozXYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = train_df[train_df.is_duplicate == 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jis1bF9zXYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x[x.scores_pow2 > 0.8][['q1_tokens','q2_tokens']].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOQodQV1zXZB",
        "colab_type": "text"
      },
      "source": [
        "## 4 .Creating Vocabulary and WordEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9nghQo4zXZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "glove = './embeddings/glove.840B.300d.txt'\n",
        "glove_embed = load_embed(glove)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_Qz46IvGto6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9FVfLE97PDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('./processed_with_weights.csv')\n",
        "test_df = pd.read_csv('./processed_with_weights_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wBs-UhRJ5YV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "# loading\n",
        "try:\n",
        "  with open('tokenizer.pickle', 'rb') as handle:\n",
        "      tokenizer = pickle.load(handle)\n",
        "except:\n",
        "  tokenizer.fit_on_texts(list(train_df.q1_tokens) + list(train_df.q2_tokens) + list(test_df.q1_tokens) + list(test_df.q2_tokens))\n",
        "  # saving\n",
        "  with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VsPED3lIyD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be14b3aa-8113-41bd-83cd-8f21e0abe66d"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RSePIDSJfvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_seq_q1 = tokenizer.texts_to_sequences(train_df.q1_tokens)\n",
        "train_seq_q2 = tokenizer.texts_to_sequences(train_df.q2_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVWXnMAtLtDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_seq_q1 = tokenizer.texts_to_sequences(test_df.q1_tokens)\n",
        "test_seq_q2 = tokenizer.texts_to_sequences(test_df.q2_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE5ko4vWMeG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lens = list(map(lambda x: len(x), train_seq_q1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61U4Uw03PQcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum(np.array(lens) >= 32)*100/len(train_seq_q1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmmiP9K3Oy7z",
        "colab_type": "code",
        "outputId": "ab4d9d62-9e11-448d-e54d-f087d1ad7fd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.hist(lens, bins=100)\n",
        "plt.ylim(0,300)\n",
        "plt.xlim(30,70)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 70)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUkcMfUnqiKEvSR35f1mA+CIosUIVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1RxYn11MfOR",
        "colab_type": "text"
      },
      "source": [
        "### Create Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6pyaU-MM7Ha",
        "colab_type": "code",
        "outputId": "ff73b072-3f44-40c4-eba5-c574144a8896",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(tokenizer.index_word))\n",
        "max_features = len(tokenizer.index_word)\n",
        "maxlen = 32"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "116082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f6Qm27mJ1mY",
        "colab_type": "code",
        "outputId": "3e7f228a-f45b-416a-bdb6-d2bd149df840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "all_embs = np.stack(glove_embed.values())\n",
        "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
        "embed_size = all_embs.shape[1]\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: continue\n",
        "    embedding_vector = glove_embed.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1Lds1H-QV6n",
        "colab_type": "text"
      },
      "source": [
        "### Pad Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqez2-qGQTkG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a445fbc6-8556-4564-8e1e-6cd22471791c"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTxqQcb8JbwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_seq_q1 = pad_sequences(train_seq_q1, maxlen = maxlen)\n",
        "train_seq_q2 = pad_sequences(train_seq_q1, maxlen = maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnTqg0TTQ5r6",
        "colab_type": "code",
        "outputId": "e72a218e-6d06-4510-d474-f5cef1660199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "train_seq_q1[0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMXLCWeAaFaY",
        "colab_type": "text"
      },
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hQiLuC2cxIz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Embedding, Bidirectional, GlobalMaxPool1D, CuDNNGRU, LSTM\n",
        "from keras.layers import Dense, Dropout, Subtract, CuDNNLSTM, Lambda\n",
        "from keras.models import Model\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUro6uPL7DRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_length = maxlen\n",
        "def getModel_medium():\n",
        "  # The visible layer\n",
        "  left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
        "  right_input = Input(shape=(max_seq_length,), dtype='int32')\n",
        "\n",
        "  embedding_layer = Embedding(max_features, embed_size, weights=[embedding_matrix], input_length=max_seq_length, trainable=False)\n",
        "\n",
        "  # Embedded version of the inputs\n",
        "  encoded_left = embedding_layer(left_input)\n",
        "  encoded_right = embedding_layer(right_input)\n",
        "\n",
        "  # Since this is a siamese network, both sides share the same LSTM\n",
        "  shared_lstm = CuDNNLSTM(32,  name='lstm')\n",
        "\n",
        "  left_output = shared_lstm(encoded_left)\n",
        "  right_output = shared_lstm(encoded_right)\n",
        "\n",
        "  # Calculates the distance as defined by the MaLSTM model\n",
        "  malstm_distance = Lambda(function=lambda a: exponent_neg_manhattan_distance(a[0], a[1]),output_shape=lambda b: (b[0][0], 1))([left_output, right_output])\n",
        "\n",
        "  # Pack it all up into a model\n",
        "  model = Model([left_input, right_input], [malstm_distance])\n",
        "  print('medium')\n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIA4mZfzXrtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getModel():\n",
        "  inp_q1 = Input(shape=(maxlen,))\n",
        "  inp_q2 = Input(shape=(maxlen,))\n",
        "  embedding_layer = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)\n",
        "  x1 = embedding_layer(inp_q1)\n",
        "  x2 = embedding_layer(inp_q2)\n",
        "  BiDirRNN = Bidirectional(CuDNNLSTM(32, return_sequences=True))\n",
        "  x1 = BiDirRNN(x1)\n",
        "  x1 = GlobalMaxPool1D()(x1)\n",
        "  x2 = BiDirRNN(x2)\n",
        "  x2 = GlobalMaxPool1D()(x2)\n",
        "  x = Subtract()([x1,x2])\n",
        "  x = Dense(16, activation=\"relu\")(x)\n",
        "  x = Dropout(0.1)(x)\n",
        "  x = Dense(1, activation=\"sigmoid\")(x)\n",
        "  model = Model(inputs=[inp_q1, inp_q2], outputs=x)\n",
        "  #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA9GHO-MxOy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getModel():\n",
        "  inp_q1 = Input(shape=(maxlen,))\n",
        "  inp_q2 = Input(shape=(maxlen,))\n",
        "  embedding_layer = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)\n",
        "  x1 = embedding_layer(inp_q1)\n",
        "  x2 = embedding_layer(inp_q2)\n",
        "  BiDirRNN = Bidirectional(CuDNNLSTM(32, return_sequences=True))\n",
        "  x1 = BiDirRNN(x1)\n",
        "  x1 = GlobalMaxPool1D()(x1)\n",
        "  x2 = BiDirRNN(x2)\n",
        "  x2 = GlobalMaxPool1D()(x2)\n",
        "  malstm_distance = Lambda(function=lambda x: exponent_neg_manhattan_distance(x[0], x[1]),output_shape=lambda x: (x[0][0], 1))([x1, x2])\n",
        "  #x = Subtract()([x1,x2])\n",
        "  #x = Dense(16, activation=\"relu\")(x)\n",
        "  #x = Dropout(0.1)(x)\n",
        "  #x = Dense(1, activation=\"sigmoid\")(x)\n",
        "  model = Model(inputs=[inp_q1, inp_q2], outputs=[malstm_distance])\n",
        "  #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8NtPMF7rbc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def exponent_neg_manhattan_distance(left, right):\n",
        "  return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFnvQaDRdVBy",
        "colab_type": "code",
        "outputId": "2b23775d-411d-4f8a-dc92-c8080e7aec33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "source": [
        "model = getModel_medium()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0807 13:00:52.001415 139754273441664 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0807 13:00:52.030817 139754273441664 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0807 13:00:52.042221 139754273441664 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0807 13:00:52.053067 139754273441664 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0807 13:00:52.053881 139754273441664 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "medium\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 32)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 32, 300)      34824600    input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (CuDNNLSTM)                (None, 32)           42752       embedding_1[0][0]                \n",
            "                                                                 embedding_1[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 1)            0           lstm[0][0]                       \n",
            "                                                                 lstm[1][0]                       \n",
            "==================================================================================================\n",
            "Total params: 34,867,352\n",
            "Trainable params: 42,752\n",
            "Non-trainable params: 34,824,600\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb02dVaYdewo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "9994c7ae-ca7e-4fa2-9448-fe57b5bdd4be"
      },
      "source": [
        "from keras.optimizers import Adadelta\n",
        "optimizer = Adadelta(clipnorm=0.9, lr=0.1)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0807 13:00:56.920565 139754273441664 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0807 13:00:56.932431 139754273441664 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzF3Q4yceBZj",
        "colab_type": "code",
        "outputId": "0ba344ef-be88-49d3-d272-4e3e0d4c93ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "history = model.fit(x=[train_seq_q1, train_seq_q2], y=train_df.is_duplicate.to_numpy(), epochs=5, batch_size=128, validation_split=0.3)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 283000 samples, validate on 121287 samples\n",
            "Epoch 1/5\n",
            "283000/283000 [==============================] - 22s 78us/step - loss: 10.0205 - acc: 0.3715 - val_loss: 10.1403 - val_acc: 0.3639\n",
            "Epoch 2/5\n",
            "283000/283000 [==============================] - 18s 64us/step - loss: 10.0205 - acc: 0.3715 - val_loss: 10.1403 - val_acc: 0.3639\n",
            "Epoch 3/5\n",
            "283000/283000 [==============================] - 18s 64us/step - loss: 10.0205 - acc: 0.3715 - val_loss: 10.1403 - val_acc: 0.3639\n",
            "Epoch 4/5\n",
            "283000/283000 [==============================] - 18s 64us/step - loss: 10.0205 - acc: 0.3715 - val_loss: 10.1403 - val_acc: 0.3639\n",
            "Epoch 5/5\n",
            "283000/283000 [==============================] - 18s 64us/step - loss: 10.0205 - acc: 0.3715 - val_loss: 10.1403 - val_acc: 0.3639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03jZC9YOlICP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.is_duplicate.to_numpy()[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6dIhDp-imMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "l = model.layers[7]\n",
        "w = l.weights[0]\n",
        "sess = tf.InteractiveSession()\n",
        "sess.run(w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kylL0u0LiqF6",
        "colab_type": "code",
        "outputId": "86c9df52-1711-45a0-941c-a1958afe2cc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "model.predict([train_seq_q1[:30], train_seq_q2[:30]])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       [1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liZRKkurhVgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}